{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Detection(Sentiment Analysis) from Text Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset used: Large Moview Review Dataset (https://ai.stanford.edu/~amaas/data/sentiment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Class with the Basic Functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "###\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "###\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "class Base:\n",
    "    \"\"\"Base class that houses common utilities for reading in test data\n",
    "    and calculating model accuracy and F1 scores.\n",
    "    \"\"\"\n",
    "    def __init__(self,train_path,test_path,mix ):\n",
    "        print(\"parent class\")\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.mix = mix\n",
    "        \n",
    "    #****************************************************\n",
    "    #### Get Training Data\n",
    "    #****************************************************\n",
    "    def get_train_data(self, train_path, mix)-> pd.DataFrame:\n",
    "        '''Function to fetch train data and create a DataFrame for Training a Model'''\n",
    "        print(\"Get Training Data\")\n",
    "    \n",
    "        text = []\n",
    "        rating = []\n",
    "        try:\n",
    "            ## Get Positive Label Train Data\n",
    "            for filename in os.listdir(train_path+\"pos\"):\n",
    "                pos_data_train = open(train_path+\"pos/\"+filename, 'r' , encoding=\"ISO-8859-1\").read()\n",
    "                text.append(pos_data_train)\n",
    "                rating.append(\"1\")\n",
    "            \n",
    "            ## Get Negative Lael Train Data\n",
    "            for filename in os.listdir(train_path+\"neg\"):\n",
    "                neg_data_train = open(train_path+\"neg/\"+filename, 'r' , encoding=\"ISO-8859-1\").read()\n",
    "                text.append(neg_data_train)\n",
    "                rating.append(\"0\")\n",
    "            \n",
    "            train_dataset = list(zip(text,rating))    \n",
    "        \n",
    "            ## Shuffle Data\n",
    "            if mix:\n",
    "                np.random.shuffle(train_dataset)\n",
    "        \n",
    "            ## Create a Datafrane\n",
    "            df_train = pd.DataFrame(data = train_dataset, columns=['Review', 'Rating'])\n",
    "            return(df_train)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(\"There is an eror in get_train_data: \", e)\n",
    "            pass\n",
    "    #****************************************************\n",
    "    #### Get Test Data\n",
    "    #****************************************************\n",
    "    def get_test_data(self,test_path) -> pd.DataFrame:\n",
    "        '''Function to fetch Test data and create a DataFrame Testing Accracy of the Model'''\n",
    "        print(\"Get Test Data\")\n",
    "\n",
    "        text = []\n",
    "        rating = []\n",
    "        try:\n",
    "            ## Get Positive Label Train Data\n",
    "            for filename in os.listdir(test_path+\"pos\"):\n",
    "                pos_data = open(test_path+\"pos/\"+filename, 'r' , encoding=\"ISO-8859-1\").read()\n",
    "                text.append(pos_data)\n",
    "                rating.append(\"1\")\n",
    "            ## Get Negative Lael Train Data\n",
    "            for filename in os.listdir(test_path+\"neg\"):\n",
    "                neg_data = open(test_path+\"neg/\"+filename, 'r' , encoding=\"ISO-8859-1\").read()\n",
    "                text.append(neg_data)\n",
    "                rating.append(\"0\")\n",
    "            \n",
    "            test_dataset = list(zip(text,rating)) \n",
    "        \n",
    "            ## Create a Datafrane\n",
    "            df_test  = pd.DataFrame(data = test_dataset, columns=['Review', 'Rating'])\n",
    "            return(df_test)\n",
    "        except Exception as ex:\n",
    "            print(\"There is an eror in get_test_data: \", ex)\n",
    "            \n",
    "         #****************************************************   \n",
    "        #### Clean the Text - Data Preprocessing\n",
    "        #****************************************************\n",
    "    def clean_data(self,text) -> pd.DataFrame:\n",
    "        '''Function to clean Review Text'''\n",
    "        print(\"Data Preprocessing\")\n",
    "        stemmer= PorterStemmer()\n",
    "    \n",
    "        try:\n",
    "            # Preprocessing\n",
    "            # convert to lower case\n",
    "            clean_text =  text.str.lower()\n",
    "            # Remove Numbers\n",
    "            clean_text = clean_text.str.replace('\\d+', '')\n",
    "            # Remove trailing spaces\n",
    "            clean_text = clean_text.str.strip()\n",
    "            # Remove Punctuations\n",
    "            clean_text = clean_text.str.replace('[^\\w\\s]',' ')\n",
    "            # Remove <br>\n",
    "            clean_text = clean_text.str.replace('br', '')\n",
    "            # Remove extra space in between words\n",
    "            clean_text = clean_text.str.replace(' +', ' ')\n",
    "            # Remove Numbers\n",
    "            clean_text = clean_text.str.replace('\\d+', '')\n",
    "            # remove stop words\n",
    "            stop = stopwords.words('english')\n",
    "            stop.extend([\"movie\",\"movies\",\"film\",\"one\"])\n",
    "            clean_text =   clean_text.apply(lambda x: \" \".join(x for x in x.split() if x not in stop ))\n",
    "            # Stemming\n",
    "            #clean_text =   clean_text.apply(lambda x: \" \".join(stemmer.stem(x) for x in x.split() ))\n",
    "\n",
    "\n",
    "            return clean_text\n",
    "        except Exception as e:\n",
    "            print(\"In Exception of clean_data: \", e)\n",
    "            return None\n",
    "    #****************************************************   \n",
    "        #### Tokenize the Reviews\n",
    "    #****************************************************\n",
    "    def tokenization(df_reviews):\n",
    "        '''Tokenize the Review Text'''\n",
    "        print(\" Tokenize the Reviews\")\n",
    "        # Tokenize \n",
    "        df_reviews[\"Clean_Review\"] = df_reviews[\"Clean_Review\"].astype(str).str.strip().str.split('[\\W_]+')\n",
    "        # Initialize a CountVectorizer object: count_vect\n",
    "        count_vec = CountVectorizer(analyzer='word',tokenizer=lambda doc: doc, lowercase=False, max_df = 0.70, min_df = 100)\n",
    "        words_vec = count_vec.fit(df_reviews[\"Clean_Review\"])\n",
    "        bag_of_words = words_vec.transform(df_reviews[\"Clean_Review\"])\n",
    "        tokens = count_vec.get_feature_names()\n",
    "        df_words = pd.DataFrame(data=bag_of_words.toarray(),columns=tokens)\n",
    "        return df_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Child Class with Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionSentiment(Base):\n",
    "    \"\"\"Predict fine-grained sentiment scores using a sklearn Logistic Regression pipeline.\"\"\"\n",
    "    def __init__(self, train_path, test_path, mix):\n",
    "        super().__init__(train_path, test_path, mix)\n",
    "        print(\"Starting LogisticRegressionSentiment Model \")\n",
    "        \n",
    "        from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        self.pipeline = Pipeline(\n",
    "            [\n",
    "                ('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(solver='liblinear', multi_class='auto')),\n",
    "            ]\n",
    "        )\n",
    "    #****************************************************   \n",
    "        #### Get Accuracy Score\n",
    "    #****************************************************\n",
    "    def accuracy_score(self,Rating,Pred_Rating)-> pd.DataFrame:\n",
    "        '''Get Accuracy Score'''\n",
    "        print(\"Get accuracy score\")\n",
    "        score = accuracy_score(Rating, Pred_Rating)\n",
    "        return score\n",
    "    \n",
    "    def predict(self,train_path,mix) -> pd.DataFrame:\n",
    "        \"Train model using sklearn pipeline\"\n",
    "        print(\"Predict Sentiment \")\n",
    "        train_df = self.get_train_data(train_path, mix)\n",
    "        train_df[\"Clean_Review\"] = self.clean_data(train_df[\"Review\"])\n",
    "        learner = self.pipeline.fit(train_df[\"Clean_Review\"], train_df[\"Rating\"])\n",
    "        # Predict class labels using the learner and output DataFrame\n",
    "        test_df = self.get_test_data(test_path)\n",
    "        #test_df[\"Clean_Review\"] = self.clean_data(test_df[\"Review\"])\n",
    "        test_df['Pred_Rating'] = learner.predict(test_df['Review'])\n",
    "        score = self.accuracy_score(test_df['Rating'],test_df['Pred_Rating'])\n",
    "        print(\"Accuracy of the Logictic Regression Model is:  \",score)\n",
    "        return learner\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextBlob NaiveBayesAnalyzer Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob_Sentiment(text):\n",
    "    print(\"Starting TextBlob Sentiment Analysis\")\n",
    "    from textblob import TextBlob\n",
    "    from textblob.sentiments import NaiveBayesAnalyzer\n",
    "    \n",
    "    score =  TextBlob(text,analyzer=NaiveBayesAnalyzer()).sentiment\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emotion Detection - main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please eneter a Text to check if it represents a Positive or Negative Emotion\n",
      " \n",
      "Enter Text: I am sad that the movie ended because I was having a good nap!\n",
      " \n",
      "Starting TextBlob Sentiment Analysis\n",
      " \n",
      "As per TextBlobNaiveBayesAnalyzer, the above statement is :  neg\n",
      "It has a positivity score:  0.35  and Negativity score:  0.65\n",
      " \n",
      "Do You want to build a Logistic Regression Model and check further? (or quit to stop): yes\n",
      " \n",
      "parent class\n",
      "Starting LogisticRegressionSentiment Model \n",
      "Predict Sentiment \n",
      "Get Training Data\n",
      "Data Preprocessing\n",
      "Get Test Data\n",
      "Get accuracy score\n",
      "Accuracy of the Logictic Regression Model is:   0.88276\n",
      " \n",
      "The sentiment of the above statement is:  ['0']\n",
      " \n",
      "Do You want to try another sentence? (yes to try again or no to stop): yes\n",
      " \n",
      "Enter Text: What a wonderful day!\n",
      " \n",
      "Starting TextBlob Sentiment Analysis\n",
      " \n",
      "As per TextBlobNaiveBayesAnalyzer, the above statement is :  pos\n",
      "It has a positivity score:  0.76  and Negativity score:  0.24\n",
      " \n",
      "Do You want to build a Logistic Regression Model and check further? (or quit to stop): yes\n",
      " \n",
      "parent class\n",
      "Starting LogisticRegressionSentiment Model \n",
      "Predict Sentiment \n",
      "Get Training Data\n",
      "Data Preprocessing\n",
      "Get Test Data\n",
      "Get accuracy score\n",
      "Accuracy of the Logictic Regression Model is:   0.88276\n",
      " \n",
      "The sentiment of the above statement is:  ['1']\n",
      " \n",
      "Do You want to try another sentence? (yes to try again or no to stop): yes\n",
      " \n",
      "Enter Text: keep looking up because that's the secret of life\n",
      " \n",
      "Starting TextBlob Sentiment Analysis\n",
      " \n",
      "As per TextBlobNaiveBayesAnalyzer, the above statement is :  pos\n",
      "It has a positivity score:  0.65  and Negativity score:  0.35\n",
      " \n",
      "Do You want to build a Logistic Regression Model and check further? (or quit to stop): quit\n",
      " \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"Please eneter a Text to check if it represents a Positive or Negative Emotion\")\n",
    "    print(\" \")\n",
    "    while True:\n",
    "        input_sen = str(input(\"Enter Text: \"))\n",
    "        print(\" \")\n",
    "        score = textblob_Sentiment(input_sen)\n",
    "        print(\" \")\n",
    "        print(\"As per TextBlobNaiveBayesAnalyzer, the above statement is : \",score.classification)\n",
    "        print(\"It has a positivity score: \", round(score.p_pos,2), \" and Negativity score: \",round(score.p_neg,2))\n",
    "        print(\" \")\n",
    "        keyword = input(\"Do You want to build a Logistic Regression Model and check further? (or quit to stop): \").lower()\n",
    "        print(\" \")\n",
    "    \n",
    "        if(keyword == \"quit\"):\n",
    "            break\n",
    "        else:\n",
    "            input_sen = [input_sen]\n",
    "            train_path = \"aclImdb/train/\"\n",
    "            test_path = \"aclImdb/test/\"\n",
    "            mod_lr = LogisticRegressionSentiment(train_path,test_path,True)\n",
    "            mod = mod_lr.predict(train_path,True)\n",
    "            val = mod.predict(input_sen)\n",
    "            print(\" \")\n",
    "            print(\"The sentiment of the above statement is: \",val)\n",
    "            print(\" \")\n",
    "            key_in = input(\"Do You want to try another sentence? (yes to try again or no to stop): \").lower()\n",
    "            print(\" \")\n",
    "            if(key_in == \"no\"):\n",
    "                print(\"Thank You!\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
