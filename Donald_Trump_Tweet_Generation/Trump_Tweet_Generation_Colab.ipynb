{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Trump_Tweet_Generation.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjV8U6-YmzBY"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wADDzbeKmzBu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import sys\n",
        "import random\n",
        "####\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Activation, Embedding, LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC_tgaqxmzBz"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsWS39LQmzB0"
      },
      "source": [
        "df =  pd.read_csv(\"Donald-Tweets.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dztxAet7mzB1",
        "outputId": "63fe5cc3-4d5d-42e6-ecdc-f20186f48ddd"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7375 entries, 0 to 7374\n",
            "Data columns (total 12 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Date                                       7375 non-null   object \n",
            " 1   Time                                       7375 non-null   object \n",
            " 2   Tweet_Text                                 7375 non-null   object \n",
            " 3   Type                                       7375 non-null   object \n",
            " 4   Media_Type                                 1225 non-null   object \n",
            " 5   Hashtags                                   2031 non-null   object \n",
            " 6   Tweet_Id                                   7375 non-null   float64\n",
            " 7   Tweet_Url                                  7375 non-null   object \n",
            " 8   twt_favourites_IS_THIS_LIKE_QUESTION_MARK  7375 non-null   int64  \n",
            " 9   Retweets                                   7375 non-null   int64  \n",
            " 10  Unnamed: 10                                26 non-null     float64\n",
            " 11  Unnamed: 11                                13 non-null     float64\n",
            "dtypes: float64(3), int64(2), object(7)\n",
            "memory usage: 691.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "qfwegFMSmzB3",
        "outputId": "9096d491-369c-4969-9cc3-04b9b22fe0c9"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Tweet_Text</th>\n",
              "      <th>Type</th>\n",
              "      <th>Media_Type</th>\n",
              "      <th>Hashtags</th>\n",
              "      <th>Tweet_Id</th>\n",
              "      <th>Tweet_Url</th>\n",
              "      <th>twt_favourites_IS_THIS_LIKE_QUESTION_MARK</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>15:26:37</td>\n",
              "      <td>Today we express our deepest gratitude to all ...</td>\n",
              "      <td>text</td>\n",
              "      <td>photo</td>\n",
              "      <td>ThankAVet</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
              "      <td>127213</td>\n",
              "      <td>41112</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>13:33:35</td>\n",
              "      <td>Busy day planned in New York. Will soon be mak...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
              "      <td>141527</td>\n",
              "      <td>28654</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date      Time  ... Unnamed: 10 Unnamed: 11\n",
              "0  16-11-11  15:26:37  ...         NaN         NaN\n",
              "1  16-11-11  13:33:35  ...         NaN         NaN\n",
              "\n",
              "[2 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-aL0oMxmzB4"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcK555ksmzB5"
      },
      "source": [
        "### Convert to Lower Case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7rtqz1RmzB6",
        "outputId": "3bb17689-808c-4140-e3c1-bb90f82ebdcc"
      },
      "source": [
        "# lowercase all\n",
        "print(\"...Before...\")\n",
        "print(df['Tweet_Text'][1])\n",
        "##\n",
        "text = df['Tweet_Text'].str.lower()\n",
        "##\n",
        "print(\"...After...\")\n",
        "print(text[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...Before...\n",
            "Busy day planned in New York. Will soon be making some very important decisions on the people who will be running our government!\n",
            "...After...\n",
            "busy day planned in new york. will soon be making some very important decisions on the people who will be running our government!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5ieK7-vmzCF"
      },
      "source": [
        "### Remove the URLs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi1XD5B8mzCG",
        "outputId": "579c2c3c-18e4-424c-e266-90b55c28aba5"
      },
      "source": [
        "print(\"...Before...\")\n",
        "print(text[100])\n",
        "##\n",
        "text = text.map(lambda s: ' '.join([x for x in s.split() if 'http' not in x]))\n",
        "##\n",
        "print(\"...After...\")\n",
        "print(text[100])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...Before...\n",
            "hillary advisers wanted her to avoid supporting israel when talking to democrats: https://t.co/y7m8ivu173\n",
            "...After...\n",
            "hillary advisers wanted her to avoid supporting israel when talking to democrats:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuBUziydmzCI"
      },
      "source": [
        "### Remove short tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQoAknvZmzCJ",
        "outputId": "4142534e-9f92-4ec8-895c-906c1a22aa0c"
      },
      "source": [
        "print(\"...Before...\")\n",
        "print(len(text))\n",
        "text = text[text.map(len)>40]\n",
        "print(\"...After...\")\n",
        "print(len(text))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...Before...\n",
            "7375\n",
            "...After...\n",
            "6886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO1iRAOQmzCK"
      },
      "source": [
        "### Remove Emojis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QEruBDqmzCL",
        "outputId": "d44d359f-c998-4965-bd8a-45f35bd9a5b5"
      },
      "source": [
        "print(\"...Before...\")\n",
        "print(text[49])\n",
        "text = text.apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
        "print(\"...After...\")\n",
        "print(text[49])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...Before...\n",
            "join me tomorrow! minnesota ۢ 2pm michigan ۢ 6pm virginia ۢ 9:30p_\n",
            "...After...\n",
            "join me tomorrow! minnesota  2pm michigan  6pm virginia  9:30p_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAJDi7eGmzCM"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVTJnAtAmzCR",
        "outputId": "16d8e439-49f8-4db1-8082-25e35a0dfadf"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text)\n",
        "vocab_size = len(tokenizer.word_counts) + 1\n",
        "print(\"Total Vocabulary: \", vocab_size )\n",
        "#print(tokenizer.word_counts)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Vocabulary:  10760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JQY7rGrmzCS"
      },
      "source": [
        "### Prepare Input Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoP61MRamzCT"
      },
      "source": [
        "#### Divide the data into training and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRmqXXX8mzCU",
        "outputId": "24e09ca3-e1f4-4a4a-e9b8-2dc4c8a1de17"
      },
      "source": [
        "N = text.shape[0]\n",
        "print(\"Total Row Count: \", N)\n",
        "prop_train = 0.8\n",
        "train = int(N*prop_train)\n",
        "print(\"Training Data Count: \", train)\n",
        "test = N - train\n",
        "print(\"Test Data Count: \", test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Row Count:  6886\n",
            "Training Data Count:  5508\n",
            "Test Data Count:  1378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSVgd1ibmzCV"
      },
      "source": [
        "#### convert text into integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lMw9ggpmzCW",
        "outputId": "4abf13dc-827b-4565-8934-3add0f4eb40e"
      },
      "source": [
        "sequences, index_train, index_test = [], [], [] \n",
        "count = 0\n",
        "for irow,line in enumerate(text):\n",
        "    #print(irow, line)\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]    \n",
        "    #print(encoded)\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "        \n",
        "        if irow < train:\n",
        "            index_train.append(count)\n",
        "        else:\n",
        "            index_test.append(count)\n",
        "        count += 1\n",
        "print('Total Sequences: %d' % (len(sequences)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 114825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T16PAS7hmzCY"
      },
      "source": [
        "#### Insert padding to make each sequence of same length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIDW-yB5mzCZ",
        "outputId": "65f62f20-0f39-4596-f205-c9d7b62d1464"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "\n",
        "\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
        "print('Max Sequence Length: %d' % max_length)\n",
        "#print(sequences)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Sequence Length: 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMNUiPiMmzCa",
        "outputId": "6fdfb82e-c45d-46e4-a927-b921c1974f25"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1],sequences[:,-1]\n",
        "#print(y.shape)\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "X_train, y_train, X_test, y_test = X[index_train], y[index_train],X[index_test], y[index_test]\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(92288, 31)\n",
            "(92288, 10760)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-w7Yi2lmzCc"
      },
      "source": [
        "## Build a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO13LzszmzCd"
      },
      "source": [
        "def build_model(vocab_size,\n",
        "                input_length=1,\n",
        "                dim_dense_embedding=10,\n",
        "                hidden_unit_LSTM=5):\n",
        "    \n",
        "    \n",
        "    main_input = Input(shape=(input_length,),dtype='int32',name='main_input')\n",
        "    embedding = Embedding(vocab_size, dim_dense_embedding, \n",
        "                         input_length=input_length)(main_input)\n",
        "    x = LSTM(hidden_unit_LSTM)(embedding)\n",
        "    main_output = Dense(vocab_size, activation='softmax')(x)\n",
        "    model = Model(inputs=[main_input],\n",
        "                  outputs=[main_output])\n",
        "    #print(model.summary())\n",
        "    return(model)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR-1kPKOmzCe"
      },
      "source": [
        "model = build_model(vocab_size,\n",
        "                               input_length=X.shape[1],\n",
        "                               dim_dense_embedding=30,\n",
        "                               hidden_unit_LSTM=64)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tIF1uIuos8w"
      },
      "source": [
        "# compile network\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkT3xIvfowt-",
        "outputId": "61493dcf-c845-4282-b038-36cb10249382"
      },
      "source": [
        "# fit network\n",
        "tf_model = model.fit(X_train, y_train, \n",
        "                 validation_data = (X_test,y_test),\n",
        "                 epochs=50, verbose=2,batch_size=128)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "721/721 - 52s - loss: 4.4283 - accuracy: 0.2218 - val_loss: 7.0761 - val_accuracy: 0.1285\n",
            "Epoch 2/50\n",
            "721/721 - 52s - loss: 4.3581 - accuracy: 0.2270 - val_loss: 7.1394 - val_accuracy: 0.1287\n",
            "Epoch 3/50\n",
            "721/721 - 53s - loss: 4.2918 - accuracy: 0.2338 - val_loss: 7.1865 - val_accuracy: 0.1299\n",
            "Epoch 4/50\n",
            "721/721 - 53s - loss: 4.2281 - accuracy: 0.2407 - val_loss: 7.2305 - val_accuracy: 0.1297\n",
            "Epoch 5/50\n",
            "721/721 - 52s - loss: 4.1667 - accuracy: 0.2474 - val_loss: 7.2852 - val_accuracy: 0.1290\n",
            "Epoch 6/50\n",
            "721/721 - 53s - loss: 4.1086 - accuracy: 0.2541 - val_loss: 7.3237 - val_accuracy: 0.1303\n",
            "Epoch 7/50\n",
            "721/721 - 53s - loss: 4.0505 - accuracy: 0.2610 - val_loss: 7.3886 - val_accuracy: 0.1288\n",
            "Epoch 8/50\n",
            "721/721 - 52s - loss: 3.9973 - accuracy: 0.2667 - val_loss: 7.4409 - val_accuracy: 0.1250\n",
            "Epoch 9/50\n",
            "721/721 - 53s - loss: 3.9456 - accuracy: 0.2737 - val_loss: 7.4760 - val_accuracy: 0.1279\n",
            "Epoch 10/50\n",
            "721/721 - 54s - loss: 3.8950 - accuracy: 0.2804 - val_loss: 7.5311 - val_accuracy: 0.1242\n",
            "Epoch 11/50\n",
            "721/721 - 54s - loss: 3.8472 - accuracy: 0.2863 - val_loss: 7.5796 - val_accuracy: 0.1269\n",
            "Epoch 12/50\n",
            "721/721 - 54s - loss: 3.8017 - accuracy: 0.2920 - val_loss: 7.6267 - val_accuracy: 0.1268\n",
            "Epoch 13/50\n",
            "721/721 - 53s - loss: 3.7572 - accuracy: 0.2980 - val_loss: 7.6868 - val_accuracy: 0.1231\n",
            "Epoch 14/50\n",
            "721/721 - 53s - loss: 3.7138 - accuracy: 0.3048 - val_loss: 7.7241 - val_accuracy: 0.1250\n",
            "Epoch 15/50\n",
            "721/721 - 53s - loss: 3.6743 - accuracy: 0.3099 - val_loss: 7.7727 - val_accuracy: 0.1250\n",
            "Epoch 16/50\n",
            "721/721 - 52s - loss: 3.6336 - accuracy: 0.3149 - val_loss: 7.8145 - val_accuracy: 0.1259\n",
            "Epoch 17/50\n",
            "721/721 - 52s - loss: 3.5969 - accuracy: 0.3203 - val_loss: 7.8576 - val_accuracy: 0.1255\n",
            "Epoch 18/50\n",
            "721/721 - 53s - loss: 3.5594 - accuracy: 0.3251 - val_loss: 7.9019 - val_accuracy: 0.1261\n",
            "Epoch 19/50\n",
            "721/721 - 52s - loss: 3.5235 - accuracy: 0.3295 - val_loss: 7.9366 - val_accuracy: 0.1245\n",
            "Epoch 20/50\n",
            "721/721 - 52s - loss: 3.4889 - accuracy: 0.3347 - val_loss: 7.9788 - val_accuracy: 0.1231\n",
            "Epoch 21/50\n",
            "721/721 - 52s - loss: 3.4548 - accuracy: 0.3387 - val_loss: 8.0350 - val_accuracy: 0.1210\n",
            "Epoch 22/50\n",
            "721/721 - 52s - loss: 3.4233 - accuracy: 0.3437 - val_loss: 8.0680 - val_accuracy: 0.1204\n",
            "Epoch 23/50\n",
            "721/721 - 52s - loss: 3.3920 - accuracy: 0.3477 - val_loss: 8.1204 - val_accuracy: 0.1216\n",
            "Epoch 24/50\n",
            "721/721 - 52s - loss: 3.3613 - accuracy: 0.3524 - val_loss: 8.1535 - val_accuracy: 0.1194\n",
            "Epoch 25/50\n",
            "721/721 - 52s - loss: 3.3317 - accuracy: 0.3554 - val_loss: 8.1983 - val_accuracy: 0.1189\n",
            "Epoch 26/50\n",
            "721/721 - 52s - loss: 3.3027 - accuracy: 0.3604 - val_loss: 8.2528 - val_accuracy: 0.1191\n",
            "Epoch 27/50\n",
            "721/721 - 52s - loss: 3.2744 - accuracy: 0.3651 - val_loss: 8.2779 - val_accuracy: 0.1212\n",
            "Epoch 28/50\n",
            "721/721 - 52s - loss: 3.2473 - accuracy: 0.3693 - val_loss: 8.3252 - val_accuracy: 0.1169\n",
            "Epoch 29/50\n",
            "721/721 - 53s - loss: 3.2202 - accuracy: 0.3731 - val_loss: 8.3570 - val_accuracy: 0.1185\n",
            "Epoch 30/50\n",
            "721/721 - 53s - loss: 3.1956 - accuracy: 0.3771 - val_loss: 8.3977 - val_accuracy: 0.1194\n",
            "Epoch 31/50\n",
            "721/721 - 53s - loss: 3.1728 - accuracy: 0.3809 - val_loss: 8.4483 - val_accuracy: 0.1184\n",
            "Epoch 32/50\n",
            "721/721 - 53s - loss: 3.1444 - accuracy: 0.3846 - val_loss: 8.4719 - val_accuracy: 0.1189\n",
            "Epoch 33/50\n",
            "721/721 - 53s - loss: 3.1214 - accuracy: 0.3880 - val_loss: 8.5235 - val_accuracy: 0.1152\n",
            "Epoch 34/50\n",
            "721/721 - 53s - loss: 3.0978 - accuracy: 0.3915 - val_loss: 8.5607 - val_accuracy: 0.1149\n",
            "Epoch 35/50\n",
            "721/721 - 52s - loss: 3.0746 - accuracy: 0.3951 - val_loss: 8.6016 - val_accuracy: 0.1147\n",
            "Epoch 36/50\n",
            "721/721 - 52s - loss: 3.0534 - accuracy: 0.3969 - val_loss: 8.6461 - val_accuracy: 0.1139\n",
            "Epoch 37/50\n",
            "721/721 - 52s - loss: 3.0316 - accuracy: 0.4010 - val_loss: 8.6715 - val_accuracy: 0.1142\n",
            "Epoch 38/50\n",
            "721/721 - 52s - loss: 3.0098 - accuracy: 0.4048 - val_loss: 8.7116 - val_accuracy: 0.1150\n",
            "Epoch 39/50\n",
            "721/721 - 53s - loss: 2.9893 - accuracy: 0.4081 - val_loss: 8.7505 - val_accuracy: 0.1122\n",
            "Epoch 40/50\n",
            "721/721 - 52s - loss: 2.9694 - accuracy: 0.4109 - val_loss: 8.7942 - val_accuracy: 0.1113\n",
            "Epoch 41/50\n",
            "721/721 - 52s - loss: 2.9486 - accuracy: 0.4149 - val_loss: 8.8318 - val_accuracy: 0.1121\n",
            "Epoch 42/50\n",
            "721/721 - 53s - loss: 2.9286 - accuracy: 0.4172 - val_loss: 8.8514 - val_accuracy: 0.1141\n",
            "Epoch 43/50\n",
            "721/721 - 53s - loss: 2.9091 - accuracy: 0.4204 - val_loss: 8.8988 - val_accuracy: 0.1104\n",
            "Epoch 44/50\n",
            "721/721 - 52s - loss: 2.8917 - accuracy: 0.4224 - val_loss: 8.9374 - val_accuracy: 0.1101\n",
            "Epoch 45/50\n",
            "721/721 - 52s - loss: 2.8724 - accuracy: 0.4254 - val_loss: 8.9795 - val_accuracy: 0.1089\n",
            "Epoch 46/50\n",
            "721/721 - 53s - loss: 2.8544 - accuracy: 0.4289 - val_loss: 9.0069 - val_accuracy: 0.1093\n",
            "Epoch 47/50\n",
            "721/721 - 52s - loss: 2.8367 - accuracy: 0.4318 - val_loss: 9.0475 - val_accuracy: 0.1114\n",
            "Epoch 48/50\n",
            "721/721 - 52s - loss: 2.8201 - accuracy: 0.4337 - val_loss: 9.0798 - val_accuracy: 0.1087\n",
            "Epoch 49/50\n",
            "721/721 - 52s - loss: 2.8034 - accuracy: 0.4364 - val_loss: 9.1251 - val_accuracy: 0.1077\n",
            "Epoch 50/50\n",
            "721/721 - 52s - loss: 2.7867 - accuracy: 0.4393 - val_loss: 9.1521 - val_accuracy: 0.1087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN_9fd08mzCj"
      },
      "source": [
        "#model.save_weights('/Users/oindrilasen/WORK_AREA/Data Science/Projects/Trump_Tweet_Generation/models/trump_tweets_generator_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAj5drL-mzCl"
      },
      "source": [
        "#model.load_weights('/Users/oindrilasen/WORK_AREA/Data Science/Projects/Trump_Tweet_Generation/models/trump_tweets_generator_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA6KoP_FmzCl"
      },
      "source": [
        "### Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoIEZ9LDmzCm",
        "outputId": "1aa7cf3b-313c-4d28-c6e8-157e5fae5551"
      },
      "source": [
        "in_text = \"Donald\"\n",
        "for _ in range(100):\n",
        "    # encode the text as integer\n",
        "    enc = tokenizer.texts_to_sequences([in_text])[0]\n",
        "    #print(enc)\n",
        "    # pre-pad sequences to a fixed length\n",
        "    enc_padding = pad_sequences([enc], maxlen=max_length-1, padding='pre')\n",
        "    #print(enc_padding)\n",
        "    probs = model.predict(enc_padding, verbose=0).flatten()\n",
        "    #print(probs)\n",
        "    index = np.random.choice(range(len(probs)),p=probs)\n",
        "    #print(index)\n",
        "    index_word = {v: k for k,v in tokenizer.word_index.items()}\n",
        "    word = index_word[index] \n",
        "    in_text += ' ' + word\n",
        "print(in_text)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Donald trump a wednesday iowa see you to see you soon a wonderful evening in massachusetts makeamericagreatagain trump2016 supersaturday rally what was so much for the big and spirited crowd realdonaldtrump trump2016 unifying the fact that is not borders lying her husband they decide better trade deals online 2vote trump in our end number of two poll results pundits in paper pundits about their place seat in history resulted arriving dept story comes now shoulder to talk including 1million debate laugh weu amazing event phyllis great terrific date u s s speech arriving 16 congress stands for new anger and role\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01WyCyZQmzCn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-IdM-a9mzCo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlwMKFdqmzCs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef6WBYfwmzCt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}